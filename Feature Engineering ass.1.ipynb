{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d48d02a-bf13-461e-b5f0-e7e6cd96dedc",
   "metadata": {},
   "source": [
    "# Feature Engineering Assignment-1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516bdaf7-5326-4a76-bf2c-2f1e00a9194b",
   "metadata": {},
   "source": [
    "Q1. What is the Filter method in feature selection, and how does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f894d7-191c-401c-8471-73e5b39051ff",
   "metadata": {},
   "source": [
    "The feature method is a technique used in feature selection to identify and select relevent feature based on their statistical properties.It involves evaluating the characteristic of each feature inpendently of the target variable.The filter method includes some following steps:-\n",
    "\n",
    "1) Feature Ranking: \n",
    "\n",
    "Calculate a statistical metric for each feature to rank them based on their individual relevance or importance. Common metrics include correlation, mutual information, chi-squared, and ANOVA, depending on the nature of the data.\n",
    "\n",
    "2) Thresholding:\n",
    "\n",
    "Set a threshold value for the selected metric. Features that meet or exceed this threshold are considered relevant and retained, while those below the threshold are discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ce3215-bb77-45d3-a501-0e627b75608e",
   "metadata": {},
   "source": [
    "Q2. How does the Wrapper method differ from the Filter method in feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaca58a-0362-45dc-85f6-4546eef8932b",
   "metadata": {},
   "source": [
    "The Wrapper method and filter method both are techniques used in feature selection but they differ in their approach to evaluate feature subsets.\n",
    "\n",
    "1) Wrapper method:\n",
    "\n",
    ". Search Strategy: The wrapper method evaluates different subsets of features by using a specific machine learning algorithm's performance as a criterion.\n",
    "\n",
    ". Computational Intensity: Wrapper methods are computationally more expensive compared to filter methods because they involve training and evaluating a machine learning model for each subset of features.\n",
    "\n",
    "2) Filter method:\n",
    "\n",
    ". Independence of the Model: The filter method evaluates features based on their individual characteristics and statistical properties without involving a specific machine learning algorithm.\n",
    "\n",
    ". Feature Ranking: It ranks features based on metrics such as correlation, mutual information, chi-squared, etc., without considering how these features perform within a particular model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a758b63-2e3b-4d8b-9430-85fdda497281",
   "metadata": {},
   "source": [
    "Q3. What are some common techniques used in Embedded feature selection methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157cf85f-3e57-4820-b29b-f0581d821867",
   "metadata": {},
   "source": [
    "1) LASSO:\n",
    "\n",
    "Type: Regularization method.\n",
    "\n",
    "Objective: LASSO adds a penalty term to the linear regression objective function, encouraging the model to shrink the coefficients of irrelevant features to zero.\n",
    "\n",
    "Outcome: Features with non-zero coefficients are selected, and the others are effectively excluded.\n",
    "\n",
    "2) Elastic Net:\n",
    "\n",
    "Type: Regularization method.\n",
    "\n",
    "Objective: Elastic Net combines L1 (LASSO) and L2 (ridge) regularization penalties. It addresses some limitations of LASSO, such as selecting only one feature from a group of highly correlated features.\n",
    "\n",
    "Outcome: Similar to LASSO, some coefficients become exactly zero, leading to feature selection.\n",
    "\n",
    "3) Tree-based Methods:\n",
    "\n",
    "Type: Ensemble methods.\n",
    "\n",
    "Objective: Decision trees inherently perform feature selection by considering the importance of features when making splits.\n",
    "\n",
    "Outcome: Features are ranked by their importance, and less important features can be pruned during the model-building process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac21db0-bfc6-420b-b941-0b8046e521fb",
   "metadata": {},
   "source": [
    "Q4. What are some drawbacks of using the Filter method for feature selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25a1cfd-9116-45d9-85c5-f1717f68fd11",
   "metadata": {},
   "source": [
    "While using the filter method for feature selection has it's advantage but it also comes with some drawbacks.Here are some drawbacks associated with filter method.\n",
    "\n",
    "1) May Lead to Overfitting:\n",
    "\n",
    "Issue: Selecting features based on statistical metrics alone may lead to overfitting to the training data.\n",
    "\n",
    "Consequence: The selected feature subset may not generalize well to new, unseen data.\n",
    "\n",
    "2) Ignores Feature Interactions:\n",
    "\n",
    "Issue: The filter method evaluates features independently of each other, meaning it may not capture interactions or dependencies between features.\n",
    "\n",
    "Consequence: Important synergies between features may be overlooked, potentially leading to suboptimal feature subsets.\n",
    "\n",
    "3) Sensitivity to Feature Scaling:\n",
    "\n",
    "Issue: Filter methods can be sensitive to the scale of features.\n",
    "\n",
    "Consequence: Features with larger scales might have a higher impact on the selected metric, potentially biasing the feature selection process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314589a9-7ddb-4682-bae4-4047456fe67c",
   "metadata": {},
   "source": [
    "Q5. In which situations would you prefer using the Filter method over the Wrapper method for feature\n",
    "selection?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04901833-9aa1-4d32-bab2-d7a5ea1d7a68",
   "metadata": {},
   "source": [
    "When i have a larger dataset where the number of feature is larger than the number of instances , also  in Exploratory data analysis(EDA) When our goal is to perform quick exploratory data analysis and identify relevant feature.In these situations i would prefer using filter method over the wrapper method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed8337-690e-46f3-ab4a-69310930f367",
   "metadata": {},
   "source": [
    "Q6. In a telecom company, you are working on a project to develop a predictive model for customer churn.\n",
    "You are unsure of which features to include in the model because the dataset contains several different\n",
    "ones. Describe how you would choose the most pertinent attributes for the model using the Filter Method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4388d7-f2d8-4cf2-99b2-ea1f3ef69e06",
   "metadata": {},
   "source": [
    "In this condition i will do several steps.First i will understand the dataset first and the features it containing.identify the targer variable.After this Handling the missing values.Deal with any missing values in the dataset because we must need a clean dataset to do further analysis.Then perform One-hot encoding if dataset contain categorical variable we need to convert them a into numerical variable.Then check correlation with target variable the higher the correlation is we will take those feature.Then perform chi-square test.Then will select the top feature that relating well with the target variable.If two or more features are highly correlated with each other, consider removing one of them to avoid multicollinearity issues.Once you have the selected features,use them a create a generalized model.you can choose a suitable machine learning algorithm based on the nature of your dataset and the requirement of your project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6a5605-a186-4c1a-9e1c-952ab80707e6",
   "metadata": {},
   "source": [
    "Q7. You are working on a project to predict the outcome of a soccer match. You have a large dataset with\n",
    "many features, including player statistics and team rankings. Explain how you would use the Embedded\n",
    "method to select the most relevant features for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a268b1-07ac-430c-bcb3-9d5d5a1d72e7",
   "metadata": {},
   "source": [
    "Select a machine learning algorithm that inherently provides a measure of feature importance during the training process. Ensemble methods like Random Forests, Gradient Boosted Trees, and some linear models are examples of algorithms that include feature importance as part of the model training.Clean and preprocess the dataset, handling missing values and encoding categorical variables if necessary.Split the dataset into training and testing sets to evaluate the model's performance.Choose a model that is suitable for the prediction task. In the case of soccer match outcome prediction, ensemble methods like Random Forests or Gradient Boosted Trees are commonly used due to their ability to capture complex relationships in the data.Train the selected model on the training dataset. During the training process, the model will assign importance scores to each feature based on how much they contribute to predicting the target variable (match outcome in this case).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac73e74-80ff-4811-bba3-51a943412a47",
   "metadata": {},
   "source": [
    "Q8. You are working on a project to predict the price of a house based on its features, such as size, location,\n",
    "and age. You have a limited number of features, and you want to ensure that you select the most important\n",
    "ones for the model. Explain how you would use the Wrapper method to select the best set of features for the\n",
    "predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11d893c-8309-4ef6-8e67-8ff0379e16a0",
   "metadata": {},
   "source": [
    "Start by selecting a machine learning model that is suitable for regression tasks, given that you are predicting the price of a house. Linear regression is a common choice, but you can also explore other models like decision trees, random forests, or gradient boosting.Clean and preprocess the dataset, handling missing values and encoding categorical variables if necessary.Split the dataset into training and testing sets to evaluate the model's performance.Choose the same model that you plan to use for the final prediction as the model for Recursive Feature Elimination (RFE).Use RFE to recursively train the model with different subsets of features and evaluate their performance. RFE works by ranking features based on their importance and eliminating the least important ones in each iteration until the desired number of features is reached.Train the model using the selected features and evaluate its performance on the testing set. Keep track of the performance metrics, such as mean squared error, mean absolute error, or R-squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d4d280-19ad-43fe-b6b4-c51544d576aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
